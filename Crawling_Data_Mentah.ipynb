{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPObLAD2rYIBz6f3cnlvt0T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhani43/KNN-Model-TFRF-Dinamic-Crawling-Youtube/blob/main/Crawling_Data_Mentah.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMFFTlnzPrJZ"
      },
      "source": [
        "**1. INSTALL REQUIREMENT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPFPDXrPzN5v"
      },
      "outputs": [],
      "source": [
        "!pip install pandas numpy scikit-learn openpyxl nltk google-api-python-client Sastrawi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwL36FB9QaLC"
      },
      "source": [
        "**2. IMPORT REQUIREMENT**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import pickle\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from google.colab import files, drive\n",
        "from googleapiclient.discovery import build"
      ],
      "metadata": {
        "id": "7WJsKzRVqNKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. CRAWLING DATA**"
      ],
      "metadata": {
        "id": "UgrqrN61Pz6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_comments(api_key, video_ids):\n",
        "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
        "\n",
        "    # Inisialisasi list untuk menyimpan semua komentar dari semua video\n",
        "    all_comments = []\n",
        "\n",
        "    for video_id in video_ids:\n",
        "        # Inisialisasi parameter untuk paginasi\n",
        "        next_page_token = None\n",
        "\n",
        "        # Loop untuk mengambil semua halaman komentar dari video saat ini\n",
        "        while True:\n",
        "            try:\n",
        "                # Lakukan request untuk mendapatkan data komentar\n",
        "                response = youtube.commentThreads().list(\n",
        "                    part=\"snippet\",\n",
        "                    videoId=video_id,\n",
        "                    textFormat=\"plainText\",\n",
        "                    pageToken=next_page_token\n",
        "                ).execute()\n",
        "\n",
        "                # Lakukan loop untuk menambahkan komentar ke dalam list\n",
        "                for item in response[\"items\"]:\n",
        "                    comment = item[\"snippet\"][\"topLevelComment\"]\n",
        "                    author = comment[\"snippet\"][\"authorDisplayName\"]\n",
        "                    text = comment[\"snippet\"][\"textDisplay\"]\n",
        "                    published_at = comment[\"snippet\"][\"publishedAt\"]\n",
        "                    comment_time = datetime.strptime(published_at, \"%Y-%m-%dT%H:%M:%SZ\")\n",
        "                    all_comments.append({\"Time\": comment_time, \"Author\": author, \"Comment\": text})\n",
        "\n",
        "                    # Periksa apakah ada balasan untuk komentar ini\n",
        "                    if \"replies\" in item:\n",
        "                        for reply in item[\"replies\"][\"comments\"]:\n",
        "                            reply_author = reply[\"snippet\"][\"authorDisplayName\"]\n",
        "                            reply_text = reply[\"snippet\"][\"textDisplay\"]\n",
        "                            reply_published_at = reply[\"snippet\"][\"publishedAt\"]\n",
        "                            reply_time = datetime.strptime(reply_published_at, \"%Y-%m-%dT%H:%M:%SZ\")\n",
        "                            all_comments.append({\"Time\": reply_time, \"Author\": reply_author, \"Comment\": reply_text})\n",
        "\n",
        "                # Periksa apakah masih ada halaman komentar berikutnya\n",
        "                next_page_token = response.get(\"nextPageToken\")\n",
        "                if not next_page_token:\n",
        "                    break  # Keluar dari loop jika tidak ada halaman berikutnya\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred: {e}\")\n",
        "                print(\"Retrying in 5 seconds...\")\n",
        "                time.sleep(30)  # Tunggu 30 detik sebelum mencoba lagi\n",
        "\n",
        "    # Simpan data komentar ke dalam file Excel\n",
        "    df = pd.DataFrame(all_comments)\n",
        "    df.to_excel(\"NewComments.xlsx\", index=False)\n",
        "    print(\"Comments saved to 'NewComments.xlsx'\")\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    api_key = \"AIzaSyC216MP_3O1-VblW-zDAxweSUuAoRJ1U2I\"\n",
        "    video_ids = [\"c545HEI7OAU\", \"x7wSRgwMIpU\", \"l_kOERYYUkg\"]\n",
        "    get_video_comments(api_key, video_ids)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "IhhqUk0iUC3G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}